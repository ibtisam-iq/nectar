# Docker Commands Cheat Sheet

## Docker System Setup

```bash
sudo groupadd docker	
sudo usermod -aG docker $USER		
groups $USER

systemctl start docker	# SSD
service docker start/stop/status	
systemctl --user <> docker-desktop
systemctl start docker; systemctl start docker.socket; systemctl --user start docker-desktop
systemctl list-units --type=service | grep docker

docker pull portainer/portainer-ce
docker volume create portainer_data
docker run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data portainer/portainer-ce  #  https://localhost:9443
```
**Docker Plugins**

- buildx
- compose
- debug
- desktop
- dev
- extension
- feedback
- init
- sbom
- scout

**Docker CLI Commands**

- container
- image
- volume
- network
- system: df, events, info, prune
- login/logout: login, logout
- plugin: plugin, context, search
- version
- stats
- manifest

```bash
docker Container Commands

  attach      Attach local standard input, output, and error streams to a running container
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  exec        Execute a command in a running container
  export      Export a container's filesystem as a tar archive
  inspect     Display detailed information on one or more containers
  kill        Kill one or more running containers
  logs        Fetch the logs of a container
  ls          List containers
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  prune       Remove all stopped containers
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  run         Create and run a new container from an image
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  wait        Block until one or more containers stop, then print their exit codes

**docker image**

  build       Build an image from a Dockerfile
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Display detailed information on one or more images
  load        Load an image from a tar archive or STDIN
  ls          List images
  prune       Remove unused images
  pull        Download an image from a registry
  push        Upload an image to a registry
  rm          Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE

**docker run & exec**

-a, --attach list          Attach to STDIN, STDOUT or STDERR
    --cap-add list         Add Linux capabilities	--cap-add MAC_ADMIN ubuntu sleep 3600
    --cap-drop list        Drop Linux capabilities	--cap-drop KILL ubuntu sleep 3600
-d, --detach               Run container in background and print container ID
-e, --env list             Set environment variables
    --env-file list        Read in a file of environment variables
    --expose list          Expose a port or a range of ports
    --entrypoint string    Overwrite the default ENTRYPOINT of the image
-i, --interactive          Keep STDIN open even if not attached
    --mount mount          Attach a filesystem mount to the container
    --name string          Assign a name to the container
    --network network      Connect a container to a network
-p, --publish list         Publish a container's port(s) to the host
-P, --publish-all          Publish all exposed ports to random ports
    --privileged=true      Give extended privileges to the command
-q, --quiet                Suppress the pull output
    --read-only            Mount the container's root filesystem as read only
    --restart string       Restart policy to apply when a container exits (def "no") --restart always --restart=on-failure:3
    --rm=ture      	       Automatically remove container & its associated anonymous volumes when it exits
-t, --tty                  Allocate a pseudo-TTY
-u, --user string          Username or UID (format: <name|uid>[:<group|gid>])
-v, --volume list          Bind mount a volume
    --volumes-from list    Mount volumes from the specified container(s)
-w, --workdir string       Working directory inside the container

**docker build**

    --build-arg stringArray         Set build-time variables
-f, --file string                   Name of the Dockerfile (default: "PATH/Dockerfile")
    --label stringArray             Set metadata for an image
    --network string                Set the networking mode for the "RUN" instructions during build (default "default")
    --no-cache                      Do not use cache when building the image 	--no-cache=true
-q, --quiet                         Suppress the build output and print image ID on success
-t, --tag stringArray               Name and optionally a tag (format: "name:tag")
--target string                     Set the target build stage to build 	--target=prod

**docker commit**

-a, --author string    Author (e.g., "Ibtisam <loveyou@ibtisam.com>")
-c, --change list      Apply Dockerfile instruction to the created image
-m, --message string   Commit message
-p, --pause            Pause container during commit (default true)

**ps & images**

-a, --all		      Show all containers/images (default shows just running)
-a, --all             Show all images (default hides intermediate images)
-f, --filter filter   Filter output based on conditions provided “dangling=true”	“status=exited”
    --format string   Format output using a custom template: 'table' 'table TEMPLATE' 'json' 'TEMPLATE'
-n, --last int        Show n last created containers (includes all states) (default -1)
-l, --latest          Show the latest created container (includes all states)
    --no-trunc        Don't truncate output of container/image
-q, --quiet           Only display container/image IDs
-s, --size            Display total file sizes

**pull/push**

-a, --all-tags         Download all tagged images in the repository
-q, --quiet            Suppress verbose output

**login/logout**

-p, --password string   Password
    --password-stdin    Take the password from stdin
-u, --username string   Username

List: 		    --volumes-from <> --volumes-from <> busybox OR --volumes-from cont1,cont2 busybox
String: 		refers to a single value, docker run -it --name <> -w /app node:alpine /bin/sh 
stringArray:	docker build --build-arg <ARG_NAME>=<value> --build-arg <ARG_NAME2>=<value2> .
```
```bash
# common commands

docker images
docker image ls 	
docker image ls node 	
docker images -f “dangling=true”
docker ps		
docker ps -a -q	docker system prune
docker ps/images/container
docker rm CONTAINERID		
docker rm $(docker ps -a -q)	
docker ps -aq | xargs docker rm	
docker volume rm VOLID
docker rmi IMAGEID/REPOSITORY:v --force

# docker pull, push, tag

docker image pull hello-world	docker pull --all-tags  image_name
docker tag OLDREPOSITORY:v mibtisam/NEWREPOSITORY:v		docker tag IMAGE_ID my-app:1.0
docker push NEWREPOSITORY:v

# docker build

docker build -t IMAGENAME:version /path		t=tag			
docker build -t img1:sam  /home/osboxes/ibtisam/docker/files		ERROR	    {Dockerfile1}
docker build -t img1:sam  .								            ERROR	    {Dockerfile1}
docker build -t img1:sam  /home/osboxes/ibtisam/docker/files		EXECUTED	{Dockerfile}
docker build -t img1:sam  .								            EXECUTED	{Dockerfile}
docker build -t img:sam -f ../../../Dockerfile1 /home/osboxes/ibtisam/docker/files
					{dockerfile path}		{folder path = docker context}
docker build -t img:sam -f ../../../Dockerfile2 /home/osboxes/ibtisam/docker/files

# docker commit

docker commit -a "Ibtisam" -m "Nginx container with custom CMD, ENV, and exposed port" \
    -c 'CMD ["nginx", "-g", "daemon off;"]' \
    -c 'ENTRYPOINT ["nginx", "-g", "daemon off;"]' \
    -c 'ENV APP_ENV=production PORT=8080' \
    -c 'WORKDIR /usr/src/app' -c 'EXPOSE 8080' \
    -c 'USER nginx' \
    -c 'LABEL version="1.0" description="Custom Nginx image"' \
    -c 'VOLUME ["/data"]' <container_id/name> <image>

# docker run

docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
docker container run = docker container create + docker container start + docker container attach
CMD can be overridden; but ENTRYPOINT can’t. # Lec-20
docker run --name <> --entrypoint sleep -d alpine infinity		entrypoint=sleep, arg=infinity
docker run --name <> --entrypoint <> nginx 10	# Dr_f: ENTRYPOINT [“sleep”] CMD [“5”], will override both ENTRYPOINT & CMD mentioned in Dr_f	# docker run --name abc --entrypoint echo nginx ibtisam
docker container run --rm -d --name <> REPOSITORY:v	
docker run -dit --name myfirstcon REPOSITORY:v /bin/sh	[COMMAND] (/bin/sh) 
docker run -dit --name myfirstcon REPOSITORY:v uname -a	[COMMAND] (uname) [ARG...] (-a)
docker run -dit --name myfirstcon alpine sleep 10		[COMMAND] (sleep) [ARG...] (10)
docker run --name <> alpine sh -c "echo hello" 		    [COMMAND] (sh) [ARG...] (-c "echo hello")
docker run alpine ls -l {by default prints the output of /root}	ls -l /usr {list /usr}
docker run --cap-add MAC_ADMIN ubuntu sleep 3600		docker run --cap-drop KILL ubuntu
docker run --user=<> ubuntu sleep 3600							user=1000
docker run -it -d --name <> -e PORT=$MY_PORT -p 7600:$MY_PORT --mount type=bind,src=$PWD/src,dst=/app/src node:$MY_ENV

# port mapping

docker run -it --name {} -p 8080:80 nginx /bin/sh	host/client:server/container
docker run -it --name web1 -p 80:80 nginx 		    YES
docker run -it --name web2 -p 80:80 nginx 		    NO mapped, but container generated. 
docker run -it --name web2 -p 8080:80 nginx 		NO mapped,because container ID exists.
docker run -it --name web3 -p 8080:80 nginx 		NOT mapped, port is already allocated.
docker run -it --name web4 -p 8081:80 nginx 		YES
docker run --rm -it --name nginx1 -d -p 127.0.0.1:80:8081/tcp nginx 80 on local to 8081 inside cont

# docker volume

docker volume create/inspect/ls/prune/rm <>	
docker volume, docker bind (bind mount), tmpfs
/var/lib/docker/image/overlay2/imagedb/metadata/sha256 (build)
/var/lib/docker/image/overlay2/imagedb/content/sha256 (All)
docker run -it --name cont1 -v /Vo1 alpine /bin/sh
Yes, all commands are essentially the same. They all create a new container named cont1 from the alpine image, start a shell in the container, and mount a volume named my-vol at the path /Vol in the container.
docker create volume my-vol
docker run -it --name cont1 --mount type=volume,source=my-volume,target=/Vol alpine /bin/sh
docker run -it --name cont1 --mount source=my-vol,target=/Vol alpine /bin/sh 	"Type": "volume"
docker run -it -d --name con1 --mount src=my-vol,dst=/Vol alpine				"Type": "volume"
docker run -it --name cont1 -v my-volume:/Vol alpine /bin/sh				    "Type": "volume"
docker run -it --name cont2 -v /HOST/PATH:/CONTAINER/PATH alpine /bin/sh		"Type": "bind"
ibtisam@mint-dell:~/dockr$ mkdir bind			/home/ibtisam/dockr/bind
docker run -it --name cont2 --mount type=bind,source=/../../,destination=/opt/data alpine /bin/sh
docker run -it --name cont-v3 -v /home/ibtisam/ct/doc-ker/docker-bind:/opt/data busybox /bin/sh & docker run -it --name cont-v4 -v /home/ibtisam/ct/doc-ker/docker-bind:/opt/data busybox /bin/sh; more than one container (with same everything) can be mounted on the same destination, all containers will share the same ONE path. Unlike docker bind, in docker volumes, all the containers have a unique volume ID, so containers can’t share the data.
docker run -d -it --name cont3 --mount type=tmpfs,destination=/app alpine /bin/sh
docker run -d -it --name cont3 --tmpfs /app alpine /bin/sh
docker create -v /dbdata --name lec-18 postgres:13-alpine /bin/true cont (lec-18) created, but exited.
docker run -d -it --name db1 --volumes-from lec-18 postgres:13-alpine /bin/sh
docker run -d -it --name db2 --volumes-from lec-18 postgres:13-alpine /bin/sh
docker run -it --name container2 --privileged=true --volume-from container1 ubuntu bin/bash
-v /home/ec2-user(host):/rajput(container) --privileged=true (container to host volume mounting)

# docker network

docker connect/create/disconnect/inspect/ls/prune/rm <>

# Monitoring & Debugging

docker exec -it CONTAINERID /bin/sh
docker start/stop/kill/pause/unpause CONTAINERID
docker start --attach CONTAINERID  (it also prints the message; docker run hello)
docker start (docker ps) docker diff <container>
docker container logs/inspect/port CONTAINERID/NAME 	
docker logs -f CONTAINERID
docker inspect <> | python3 -c "import sys, yaml, json; yaml.safe_dump(json.load(sys.stdin), sys.stdout, default_flow_style=False)" > abc.yaml
docker search <image name to be searched from hub>

# docker compose

https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-ubuntu-20-04 
https://docs.docker.com/compose/ 		https://github.com/docker/compose

sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose;	sudo chmod +x /usr/local/bin/docker-compose 
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose; docker-compose --version
# if ln -s isn’t created;	/usr/local/bin/docker-compose --version
https://docs.docker.com/reference/compose-file/legacy-versions/ 
up -d; ps -a; down;
```
**Key Points**

- docker run, always use -it, if you later want to enter (docker exec) into the container, otherwise docker start doesn't start it to exec. /bin/sh (better to add)
- To be in ps, -it isn’t mandatory; docker start exec
- Kill/stop the container. Remove/Delete the container. Remove/Delete the image.
- Once you exit the running container, you need to start it again before running exec.
- docker start/exec {containerID}, unlike the run command, container stops only if stopped.
- docker run `exit` exited; but docker start/exec `exit` NOT EXited, until you stop it.
- docker run/build `NO ContainerID`, exec/start/stop/kill/commit/inspect/logs `ContainerID`
- docker run doesn’t require a path, but docker build requires a path.
- docker start {containerID}, it just starts the container, but can’t print the output.
- To print the message, docker start --attach {containerID}
- To run the same container, start --attach directly instead of exec
- docker commit, whether you make changes in container or not, each commit command generates a new image ID.
- docker build, image layers are read-only. Image layers = no of lines in Dockerfile 
- While building, if any error occurs at any layer, it will not proceed next, but create the image with `none` tag and finish it.
- docker build . dangling image; NO image Name & TAG,but contains Image ID. 
- docker images alpine; docker build with RUN alpine; docker images, NO alpine 
- ImageName, always be in lower case.
- ls -l, just print the output after exiting. docker run alpine ls -l
- dagling image = `repo & tag = none`, but imageID allocated
- /var/run/docker.sock this file connects docker client with server/daemon. If the server is off, pa -a doesn’t show any result.
- -- rm, name, attach, version, help, all
- docker run -it & -dit, /bin/sh is not mandatory. -it leads to /boot by default.
- docker exec -it & -dit, /path isn’t mandatory.	docker exec {container ID} ls
- docker exec, -it is mandatory along with /path, if you enter into the container.
- build, /Dockerfile path is mandatory.
- run `<ls -l> <bin/sh> <bin/ash> <echo “this is ibtisam”>`
- To go into the container, add -it. Or add --attach while starting the container for print.
- Image ID NOT changed, `<deletion> <tagging> <pushing>`
- Image ID CHANGED, `<changes in Dockerfile> <commit, even you made no changes in container>`
- Image ID Created, `<build>, <pull>, <commit>`
- --name cont1 -v /VOL alpine		--name cont2 -v /VOL alpine; possible
- /VOL (the same destination) can be used to mount for n volumes
- containers -v (n) = volumes (n) , same destination no problem, but containers can’t share the data due to the unique volume ID assigned to each one.
- In docker volume, different container IDs, different Volume Ids, data not shared
- In docker bind, different container IDs, no Volume ID, data shared
- docker run -d --rm -p 8080:8080 --name webserver busybox sh -c "while true; do { echo -e 'HTTP/1.1 200 OK\r\n';echo 'smallest http server'; } | nc -l -p 8080; done"
- docker ps -a	 or docker port CONTAINERID	
- netstat -tuln | grep 8080	OR	ss -tuln | grep 8080
- curl http://localhost:8080 or http://192.168.100.107:8080/
- docker run -dit -p 8080:80 --name myser nginx		YES
- docker run -dit -p 8080:80 --name myser1 nginx		NO, port allocated

# Dockerfile

```bash
# FROM <image>[:<tag>]
# Specifies the base image to use for the subsequent instructions.

FROM alpine

# MAINTAINER my Ibtisam

# Adds metadata to an image (key-value pairs).

LABEL version="1.0" description="My application" maintainer="John Doe john@example.com"

# Define build-time argument which can be used in builds.
# Defines a variable that users can pass at build-time to the builder with the docker build command.
# After the image is built, the ARG value is no longer available.
# 
# You can set it during the build process with the --build-arg flag. 
# If not specified, it defaults to the value you provided (in this case, 8000).
# docker build --build-arg PORT=4000 -t myapp .

ARG VERSION=1.0
AGR PORT=8000

# Set environment variables that can be accessed by the application.
# ENV <key> <value>
# Application in the container is configured to listen on this port, so you should EXPOSE the same port
ENV APP_ENV=production
ENV PORT=8000
ENV PORT=$PORT

# Set the working directory in the container where the application code will reside.
# Sets the working directory for any RUN, CMD, ENTRYPOINT, COPY, and ADD instructions that follow it.
WORKDIR /app

# Copy all files from the current directory on the host to the /app directory in the container.
#COPY <src> <dest>
COPY . /app

# ADD <src> <dest>
# Similar to COPY, but can also extract TAR files and supports remote URLs.
ADD myapp.tar.gz /app/


# Executes linux commands to install necessary packages or dependencies
# CMD, to run any command like systemctl; RUN, to install anything
# RUN <command> # Executes commands in a new layer on top of the current image and commits the results.

RUN echo "Hey sweetheart" 
RUN echo "This is Ibtisam."
RUN echo $(pwd)
RUN touch file.txt
RUN apt-get update 
RUN cd /tmp && touch abc.txt
RUN echo "Hey sweetheart" && echo "This is Ibtisam." && echo $(pwd) && touch file.txt && apt-get update && cd /tmp && touch abc.txt


# Make port 8000 available to the world outside this container
# Informs Docker that the container listens on port 8000 at runtime.
# While it does not actually publish the port, it serves as documentation and helps with network configuration.
# You still need to use the -p option when running the container to make that port accessible from your host.
# This instruction doesn't automatically make the port accessible from outside the container, 
# but it signals to tools like Docker Compose or Kubernetes that port 8000 is the expected point of access.
# So, the EXPOSE instruction is a way to declare which ports your application uses, 
# and it works hand-in-hand with the -p option when running the container to establish the actual port mapping.
# docker run -p 4000:8000 my-app
# container=8000, host=4000, curl http://localhost:4000  -p 4000:8000
# Make it sure that the application is configured to listen on the same port.
# Not mentioning EXPOSE during the image build doesn’t prevent the container from being able to listen on a port at runtime, 
# the image can still listen on ports if you map them during docker run.
# containerPort=service's targetPort=8000,  hostPort=4000

EXPOSE 8000
EXPOSE $PORT

# Create a mount point for external storage
VOLUME ["/app/data"]

# Define the entry point for the container
# Sets the command to execute when the container starts, making it executable.
# the ENTRYPOINT is the command that always gets executed when a container starts.
#The ENTRYPOINT command defines the default program that runs when the container is started. 
#In this case, it specifies that the python3 interpreter will always be used.
#python3: This is the executable. It's the command that will always be executed when the container starts.
ENTRYPOINT ["executable"]	
ENTRYPOINT ["python3"]


# Specifies the default argument for the entry point, which runs app.py.
# app.py: This is the parameter to the python3 executable.
# The CMD provides the default arguments for the ENTRYPOINT executable. 
# In this case, app.py is passed as an argument to python3, meaning that the container will run python3 app.py by default.
CMD ["app.py"]

# CMD ["executable","param1","param2"]
# Specifies the default command to run when the container/application starts.
# No, a Dockerfile cannot have multiple CMD instructions that are executed simultaneously. Only one CMD instruction is allowed 
# in a Dockerfile, and if there are multiple CMD instructions, only the last one will take effect. 
# The CMD provides the default command that will be executed when a container is started from the image.
# Only one CMD instruction can be used; if multiple are specified, the last one takes effect.

# CMD npm start                         # ENTRYPOINT [ "npm" ] CMD [ "start" ]
# CMD ["python3", "app.py"] 
# CMD ["echo", "Hello, sweetheart"]     # ENTRYPOINT [ "echo" ] CMD [ "Hello Sweetheart" ]               

# Option 1: Use shell form (sh -c)
CMD ["sh", "-c", "npm start && python3 app.py && echo 'Hello, sweetheart' && python3 app.py"]

# Option 2: Combine commands into an entrypoint script
# You can also create a shell script (entrypoint.sh), copy it into the container, and use it as the CMD:

#!/bin/sh
npm start;  python3 app.py; echo "Hello, sweetheart"

COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN chmod +x /usr/local/bin/entrypoint.sh
CMD ["/usr/local/bin/entrypoint.sh"]

COPY run_commands.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/run_commands.sh
CMD ["/usr/local/bin/run_commands.sh"]

# Set the user to run the application (non-root for security)
# RUN useradd -m appuser
USER appuser

# Add a health check to monitor the application's status
# Defines a command to check the health of the application, ensuring it is running properly.
HEALTHCHECK --interval=30s CMD curl -f http://localhost:80/ || exit 1

# Allows the default shell used for the shell form of commands to be overridden.
# Changing the default shell to PowerShell in Windows container
SHELL ["executable", "parameters"]
SHELL ["powershell", "-command"]
```
ARG PORT=8000
ENV PORT=$PORT

- ARG PORT=8000: This sets PORT to 8000 during the build process (build-time). You can override this value when you build the Docker image using docker build --build-arg PORT=5000 . to change the port number just during the build.

- ENV PORT=$(PORT): After the build is done, this line ensures that the port you specified at build-time gets passed into the container as an environment variable.

  - application is listening on 8000, and docker also exposes 8000. Right? so, I'll map it to my localhost at 8000 to work properly? from what I understand, ENV & Expose must be the same in the docker file, and should you open the same port on your localhost?

**ChatGPT said:**
Yes, you're understanding it correctly. Here's the breakdown:

Application inside the container:
The application is configured to listen on port 8000 because of the ENV PORT=8000 in the Dockerfile.

Docker exposing the port:
Docker is set to expose port 8000 to allow access to the application from outside the container (using EXPOSE 8000).

Mapping to localhost:
When running the container, you'll need to map the container's port 8000 to a port on your localhost (host machine). 

The most straightforward way is to map it to the same port on your localhost by running:
docker run -p 8000:8000 your-image This command maps port 8000 inside the container to port 8000 on your localhost. Now, when you visit http://localhost:8000, it will route to the application running inside the Docker container.

Key Points:

ENV and EXPOSE values should generally be the same to keep everything aligned, meaning both are set to 8000 in this case.

When you map the container port to your localhost, you can use the same 8000 port on the host machine for simplicity, but you can also map to a different port if needed (e.g., -p 9000:8000 would map the container's port 8000 to port 9000 on the host).

So yes, for everything to work as expected:

The application listens on port 8000.

Docker exposes port 8000.

You map port 8000 to your localhost:8000.

In this way, accessing http://localhost:8000 on your machine will successfully reach your application.

   - so, is it mandatory to mention both ENV & AGR? what if i mentioned AGR, but don't mention ENV? or what if I mention ENV, and don't mention AGR?

**ChatGPT said:**

It’s not mandatory to mention both ARG and ENV together in a Dockerfile. They have distinct purposes and behave differently:

If you mention only ARG (without ENV):

ARG is only available during build-time (when the Docker image is being created), so if you use ARG PORT=8000, this value will only be used during the build process. Once the container is running, ARG values are no longer available. This means the application inside the container won't be able to access PORT unless you explicitly set it with ENV as well.

Result: The application in index.js won’t know about PORT at runtime because ARG is only for build-time, so it will fall back to the default in your code (4000 in this case).

If you mention only ENV (without ARG):

ENV sets environment variables for runtime (when the container is running). So if you only use ENV PORT=8000, your application will pick up this value from process.env.PORT at runtime. This means your application will listen on port 8000 without needing ARG.

Result: Your application will correctly use port 8000 because ENV passes the value to process.env.PORT at runtime.

If you mention both ARG and ENV:
ARG is used during the build to pass values that can later be set as environment variables via ENV. For example:

ARG PORT=8000
ENV PORT=$PORT

Here, ARG PORT=8000 sets a default value at build-time, and then ENV PORT=$PORT makes it available at runtime by passing the value from the ARG to ENV.

This setup allows flexibility where the build process can accept different ARG values but still make them available as ENV for the container.

Result: This ensures that both build-time and runtime configurations align. You could also override the ARG at build-time like this:

docker build --build-arg PORT=9000 -t myapp .

In Summary:

Only ARG: Used at build-time. The application won’t see it unless you pass it to ENV.
Only ENV: This is what you need for the application to get the value at runtime.
Both ARG and ENV: Flexible and allows you to pass different values during the build, which are then available at runtime.
For your case with the Node.js application, you can skip ARG if you don’t need to pass a different port at build-time and only use ENV for runtime configuration.