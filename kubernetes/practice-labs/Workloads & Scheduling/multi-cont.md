## Q1

### üîπ Requirements Breakdown

* Pod name: **`alpine-pod-pod`**
* Image: **`alpine:latest`**
* Container name: **`alpine-container`**
* Use **command**: `/bin/sh`
* Use **args**: `["-c", "tail -f /config/log.txt"]`
* Mount a **volume** named `config-volume` from an existing **ConfigMap** `log-configmap`
* Mount path: `/config`
* Restart policy: **Never**

### ‚úÖ Final YAML

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: alpine-pod-pod
spec:
  restartPolicy: Never
  containers:
  - name: alpine-container
    image: alpine:latest
    command:
    - /bin/sh
    - -c
    - tail -f /config/log.txt
    volumeMounts:
    - name: config-volume
      mountPath: /config
  volumes:
  - name: config-volume
    configMap:
      name: log-configmap
```
---

## Q2

Volume name should be `volume-share` of type `emptyDir`.

After creating the pod, exec into the first container i.e `volume-container-devops-1`, and just for testing create a file `blog.txt` with any content under the mounted path of first container i.e `/tmp/blog`.

The file `blog.txt` should be present under the mounted path `/tmp/games` on the second container `volume-container-devops-2` as well, since they are using a shared volume.

```bash
thor@jumphost ~$ k get po
NAME                  READY   STATUS    RESTARTS   AGE
volume-share-devops   2/2     Running   0          9s

thor@jumphost ~$ k exec volume-share-devops -it -c volume-container-devops-1 -- sh
sh-5.2# touch /tmp/blog/blog.txt
sh-5.2# ls /tmp/blog/blog.txt 
/tmp/blog/blog.txt
sh-5.2# exit
exit

thor@jumphost ~$ k exec volume-share-devops -it -c volume-container-devops-2 -- sh
sh-5.2# ls /tmp/games/
blog.txt
sh-5.2# 
```

---

## Q3
In the `ckad-multi-containers` namespaces, create a `ckad-neighbor-pod` pod that matches the following requirements.

Pod has an **emptyDir** volume named `my-vol`.

The first container named `main-container`, runs `nginx:1.16` image. This container mounts the `my-vol` volume at `/usr/share/nginx/html` path.

The second container is a co-located container named `neighbor-container`, and runs the `busybox:1.28` image. This container mounts the volume `my-vol` at `/var/log` path.

**Every 5 seconds**, this container should write the `current date` along with greeting message `Hi I am from neighbor container` to `index.html` in the `my-vol` volume.

```bash
root@student-node ~ ‚úñ k replace -f 1.yaml --force
pod "ckad-neighbor-pod" deleted
pod/ckad-neighbor-pod replaced

root@student-node ~ ‚ûú  cat 1.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: ckad-neighbor-pod
  namespace: ckad-multi-containers
spec:
  volumes:
    - name: my-vol
      emptyDir: {}
  containers:
    - name: main-container
      image: nginx:1.16
      volumeMounts:
        - name: my-vol
          mountPath: /usr/share/nginx/html
    - name: neighbor-container
      image: busybox:1.28
      command: ["/bin/sh", "-c"]
      args:
        - while true; do      # I made the mistake.. >> not > and /var/log/index.html not index.html
            echo "$(date) - Hi I am from neighbor container" >> /var/log/index.html;    
            sleep 5;
          done
      volumeMounts:
        - name: my-vol
          mountPath: /var/log
root@student-node ~ ‚ûú  k get po -n ckad-multi-containers 
NAME                READY   STATUS    RESTARTS   AGE
ckad-neighbor-pod   2/2     Running   0          15s

root@student-node ~ ‚ûú  k exec -n ckad-multi-containers ckad-web-pod -c  log-container -it -- cat /var/log/index.html
Mon Oct  6 22:26:45 UTC 2025 - Hi I am from neighbor container
Mon Oct  6 22:26:50 UTC 2025 - Hi I am from neighbor container
Mon Oct  6 22:26:55 UTC 2025 - Hi I am from neighbor container

---
Another way:

command:
        - /bin/sh
        - -c
        - while true; do echo $(date -u) Hi I am from neighbor container >> /var/log/index.html; sleep 5;done
```

---
## Q4

In the `cka-multi-containers` namespace, proceed to create a pod named `cka-sidecar-pod` that adheres to the following specifications:

- The first container, labeled `main-container`, is required to run the `nginx:1.27`, which writes the current `date` along with a greeting message `Hi I am from Sidecar container` to `/log/app.log`.
- The second container, identified as `sidecar-container`, must use the `nginx:1.25` image and serve the `app.log` file as a webpage located at `/usr/share/nginx/html`.

> Note: Do not rename `app.log` to `index.html`. The file name should remain `app.log` and be available at `/app.log` via the nginx server.

```bash
cluster2-controlplane ~ ‚ûú  vi 4.yaml

cluster2-controlplane ~ ‚ûú  k apply -f 4.yaml 
pod/cka-sidecar-pod created

cluster2-controlplane ~ ‚ûú  k get po -n cka-multi-containers
NAME              READY   STATUS    RESTARTS   AGE
cka-sidecar-pod   2/2     Running   0          23s

cluster2-controlplane ~ ‚ûú  cat 4.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: cka-sidecar-pod
  namespace: cka-multi-containers
spec:
  containers:
    - name: main-container
      image: nginx:1.27
      command:
        - sh
        - -c
        - |
          while true; do
            echo "$(date) - Hi I am from Sidecar container" >> /log/app.log
            sleep 5
          done
      volumeMounts:
        - name: shared-log
          mountPath: /log
    - name: sidecar-container
      image: nginx:1.25
      ports:
        - containerPort: 80
      volumeMounts:
        - name: shared-log
          mountPath: /usr/share/nginx/html/app.log
          # Keep original file name
          subPath: app.log
  volumes:
    - name: shared-log
      emptyDir: {}
---

controlplane ~ ‚ûú  k apply -f 2.yaml 
pod/cka-sidecar-pod configured

controlplane ~ ‚ûú  k get po
NAME        READY   STATUS    RESTARTS   AGE
webserver   2/2     Running   0          63m

controlplane ~ ‚ûú  cat 2.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: cka-sidecar-pod
  namespace: cka-multi-containers
spec:
  containers:
  - name: main-container
    image: nginx:1.27
    command: ["/bin/sh", "-c"]
    args: ["while true; do date >> /log/app.log; echo 'Hi I am from Sidecar container' >> /log/app.log; sleep 5; done"]
    volumeMounts:
    - name: shared-logs
      mountPath: /log

  - name: sidecar-container
    image: nginx:1.25
    volumeMounts:
    - name: shared-logs
      mountPath: /usr/share/nginx/html

  volumes:
  - name: shared-logs
    emptyDir: {}
```

### üîπ What happened in your example?

* You solved with **`emptyDir`**, not `hostPath` (see last section: `volumes: emptyDir: {}` ‚úÖ).
* That‚Äôs the correct approach for **sidecar logging / file sharing inside one Pod**.

### üîπ But what if someone uses `hostPath`?

* **Technically it will work** because both containers would still share the file via a directory on the host.
* **But**:

  * `hostPath` ties the Pod to a specific node.
  * It breaks portability (not recommended unless explicitly required).
  * CKA/CKAD examiners won‚Äôt expect you to pick `hostPath` unless the question **explicitly says ‚Äúlogs must be stored on host node path /var/log/...‚Äù**.

### üîπ Exam-safe rule

üëâ If the question is **silent** about the volume type:

* Always assume **`emptyDir`** (sidecar/multi-container scenario).
* Only use **`hostPath`** if exam says something like:

  * ‚Äústore logs under `/var/log/app` on the host‚Äù
  * ‚Äúmount host directory‚Äù
  * ‚Äúmake logs survive across Pod restarts by using node‚Äôs filesystem‚Äù

‚úÖ So in your question: `emptyDir` is the expected correct answer.
If you used `hostPath`, it would work but be **over-engineering + not best practice** ‚Üí examiners won‚Äôt want that unless asked.

---

## Q5

Create a pod named `webserver`.

Create an `emptyDir` volume `shared-logs`.

Create two containers from `nginx and ubuntu images with latest tag` only and remember to mention tag i.e nginx:latest, nginx container name should be `nginx-container` and ubuntu container name should be `sidecar-container` on webserver pod.

Add command on sidecar-container `"sh","-c","while true; do cat /var/log/nginx/access.log /var/log/nginx/error.log; sleep 30; done"`

Mount the volume `shared-logs` on both containers at location `/var/log/nginx`, all containers should be up and running.

Got it üëç Thanks for pasting the full manifest.

Here‚Äôs why the lab marked it wrong:

* In the `nginx-container`, the **volumeMount** shows `- mountPath: /var/log/nginx`.
* But in the YAML, Kubernetes interprets `/var/log/nginx` and `/var/log/nginx/` as two **different strings**.
* The grader is strict and expects exactly **`/var/log/nginx/` (with trailing slash)**.

That‚Äôs why you got ‚ùå even though functionally your pod works.

‚úÖ Corrected YAML (only the mountPath needs fixing):

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: webserver
spec:
  volumes:
    - name: shared-logs
      emptyDir: {}
  containers:
    - name: nginx-container
      image: nginx:latest
      volumeMounts:
        - name: shared-logs
          mountPath: /var/log/nginx/   # <- notice the trailing slash
    - name: sidecar-container
      image: ubuntu:latest
      command: ["sh", "-c", "while true; do cat /var/log/nginx/access.log /var/log/nginx/error.log; sleep 30; done"]
      volumeMounts:
        - name: shared-logs
          mountPath: /var/log/nginx/   # <- same here
```
> **Notes:** I tried again `mountPath: /var/log/nginx` and it works.
---

## Q6

Do the following in Namespace default:

- Create a Pod named `ready-if-service-ready` of image `nginx:1-alpine`
- Configure a LivenessProbe which simply executes command `true`
- Configure a ReadinessProbe which does check if the url http://service-am-i-ready:80 is reachable, you can use `wget -T2 -O- http://service-am-i-ready:80` for this
- Start the Pod and confirm it isn't ready because of the ReadinessProbe.

Then:

- Create a second Pod named `am-i-ready` of image `nginx:1-alpine` with label `id: cross-server-ready`
- The **already existing Service** `service-am-i-ready` should now have that second Pod as endpoint
- Now the first Pod should be in ready state, check that

```bash
controlplane ~ ‚ûú  k get svc,ep
Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
NAME                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/service-am-i-ready   ClusterIP   172.20.11.223   <none>        80/TCP    10s

NAME                           ENDPOINTS             AGE
endpoints/service-am-i-ready   <none>                10s

controlplane ~ ‚ûú  vi 1.yaml

controlplane ~ ‚ûú  k apply -f 1.yaml 
pod/ready-if-service-ready created

controlplane ~ ‚ûú  k get po
NAME                     READY   STATUS    RESTARTS   AGE
ready-if-service-ready   0/1     Running   0          5s

controlplane ~ ‚ûú  k run am-i-ready --image nginx:1-alpine -l id=cross-server-ready
pod/am-i-ready created

controlplane ~ ‚ûú  k get po
NAME                     READY   STATUS    RESTARTS   AGE
am-i-ready               1/1     Running   0          6s
ready-if-service-ready   0/1     Running   0          3m3s

controlplane ~ ‚ûú  k get po
NAME                     READY   STATUS    RESTARTS   AGE
am-i-ready               1/1     Running   0          13s
ready-if-service-ready   1/1     Running   0          3m10s

controlplane ~ ‚ûú  k get po,ep -o wide
Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
NAME                         READY   STATUS    RESTARTS   AGE     IP           NODE     NOMINATED NODE   READINESS GATES
pod/am-i-ready               1/1     Running   0          27s     172.17.2.2   node02   <none>           <none>
pod/ready-if-service-ready   1/1     Running   0          3m24s   172.17.1.2   node01   <none>           <none>

NAME                           ENDPOINTS             AGE
endpoints/kubernetes           192.168.102.92:6443   17m
endpoints/service-am-i-ready   172.17.2.2:80         9m51s

controlplane ~ ‚ûú  cat 1.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: ready-if-service-ready
  namespace: default
spec:
  containers:
  - name: nginx
    image: nginx:1-alpine
    livenessProbe:
      exec:
        command:
        - "true"
    readinessProbe:
      exec:
        command:
        - wget
        - "-T2"
        - "-O-"
        - "http://service-am-i-ready:80"

controlplane ~ ‚ûú
 
```yaml
## These formats are also correct
readinessProbe:
      exec:
        command:
        - wget
        - -T2
        - -O-
        - http://service-am-i-ready:80
readinessProbe:
      exec:
        command:
        - sh
        - -c
        - 'wget -T2 -O- http://service-am-i-ready:80'
```

---

## Q7

An existing nginx pod, `my-pod-cka` and Persistent Volume Claim (PVC) named `my-pvc-cka` are available. Your task is to implement the following modifications:

- Update the pod to include a `sidecar` container that uses the `busybox` image. Ensure that this sidecar container remains operational by including an appropriate command `"tail -f /dev/null"` .

Share the `shared-storage` volume between the main application and the sidecar container, mounting it at the path `/var/www/shared` . Additionally, ensure that the sidecar container has `read-only access` to this shared volume.

```bash
 volumes:
  - name: shared-storage
    hostPath:
      path: "/var/www/shared"
      type: DirectoryOrCreate
  - name: shared-storage
    persistentVolumeClaim:
      claimName: my-pvc-cka

controlplane:~$ k replace -f /tmp/kubectl-edit-3424260573.yaml --force
pod "my-pod-cka" deleted
The Pod "my-pod-cka" is invalid: spec.volumes[1].name: Duplicate value: "shared-storage"

  volumes:
  - name: shared-storage
    hostPath:
      path: "/var/www/shared"
      type: DirectoryOrCreate
    persistentVolumeClaim:
      claimName: my-pvc-cka

controlplane:~$ k replace -f /tmp/kubectl-edit-3424260573.yaml --force
The Pod "my-pod-cka" is invalid: 
* spec.volumes[0].persistentVolumeClaim: Forbidden: may not specify more than 1 volume type
```

Got it üëç this is a **sidecar container with shared PVC mount** use case.
Since you already have an **nginx pod (`my-pod-cka`)** and a **PVC (`my-pvc-cka`)**, we‚Äôll just update the pod spec.

Here‚Äôs how the updated `my-pod-cka` YAML would look:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod-cka
spec:
  containers:
    - name: nginx
      image: nginx
      volumeMounts:
        - name: shared-storage
          mountPath: /var/www/shared   # main container gets full access

    - name: busybox-sidecar
      image: busybox
      command: [ "sh", "-c", "tail -f /dev/null" ]
      volumeMounts:
        - name: shared-storage
          mountPath: /var/www/shared   # sidecar mounts the same PVC
          readOnly: true               # sidecar has READ-ONLY access

  volumes:
    - name: shared-storage
      persistentVolumeClaim:
        claimName: my-pvc-cka
```

Exactly üëç no need to use a `hostPath` here.

The **question already tells you**:

* A **PVC (`my-pvc-cka`)** exists.
* That PVC is already bound to some **PV**.
* Your job is just to mount that same PVC into both containers.

So this part:

```yaml
volumes:
  - name: shared-storage
    persistentVolumeClaim:
      claimName: my-pvc-cka
```

is **all that‚Äôs required** ‚úÖ

üîë Why not `hostPath`?

* `hostPath` ties storage to a specific node‚Äôs filesystem (not portable, not recommended for exam scenarios unless explicitly asked).
* Since a PVC is already provided, Kubernetes will ensure the volume is provisioned/attached from the bound PV, no need to mess with host paths.

So in your pod update, just keep the **PVC reference** exactly as you showed ‚Äî **no `hostPath` needed**.

---

In Kubernetes, each `volume` entry under `spec.volumes` must have a **unique name**. If you define two volumes with the same `name`, you‚Äôll get:

```
spec.volumes[1].name: Duplicate value: "shared-storage"
```

And if you try to add two different sources (like `persistentVolumeClaim` + `emptyDir`) under the same volume, you‚Äôll get:

```
spec.volumes[0].persistentVolumeClaim: Forbidden: may not specify more than 1 volume type
```

### How to handle your case (adding a sidecar)

If your **main container already mounts a PVC**, you don‚Äôt need to redefine the `volumes` block.

Instead, in the sidecar container, simply **reuse the existing volume** by mounting it with the same `name`.

‚úÖ Example:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod-cka
spec:
  volumes:
  - name: shared-storage              # Already defined PVC
    persistentVolumeClaim:
      claimName: my-pvc

  containers:
  - name: main-app
    image: nginx
    volumeMounts:
    - name: shared-storage
      mountPath: /usr/share/nginx/html

  - name: sidecar                     # Sidecar reuses the same volume
    image: busybox
    command: [ "sh", "-c", "echo 'Hello from sidecar' >> /data/sidecar.log; sleep 3600" ]
    volumeMounts:
    - name: shared-storage
      mountPath: /data
```

üëâ Key takeaway:

* **Never duplicate the `volumes` section** for a sidecar.
* Just mount the **existing volume** into the sidecar container.

---
